# Recommendation Systems: Ending CS BA Project
## Theorical Project in the PDF file:
Latex project made on Overleaf, with it's pdf and images available in this repository:<br/>
**Overleaf**: https://overleaf.com<br/>
**PDF**: On the root folder or in<br/>
**ArXiv**:<br/>
**Images**: On the "Images" folder<br/>
## Practical Project:
### Installing the Venv:
I called venv, and the sequence is in the requirements.txt, suposing the python venv is already installed in your device you will:<br/>
Create the venv called "firstEnv":<br/>
**python3 -m venv firstEnv**<br/>
Activate it:<br/>
**source firstEnv/bin/activate**<br/>
Install jupyter notebook that we'll need to make the work presentable.<br/>
**pip3 install jupyter**<br/>
TensorFlow version 1, for all the machine learning stuff<br/>
**pip3 install tensorflow**<br/>
Keras to make AI models even easier to implement<br/>
**pip3 install keras**<br/>
MatPlotLib for our data visualization<br/>
**pip3 install matplotlib**<br/>
TQDM for ProgressBars in out jupyter notebook or terminal<br/>
**pip3 install tqdm**<br/>
Scikit-Learn for it's extremely efficient implementations of a few famous algorithms<br/>
**pip3 install scikit-learn**<br/>
Pandas for all our dataframes and CSV manipulation<br/>
**python3 -m pip install --upgrade pandas**<br/>
Surprise for some already done recommender algorithms to compare<br/>
**pip3 install surprise**<br/>
Numpy and Scipy for dealing with large arrays<br/>
**pip3 install numpy**<br/>
**pip3 install scipy**<br/>
### Versions that I used:
Python: 3.7.3<br/>
TensorFlow: 1.14.0<br/>
Keras: 2.2.4<br/>
MatplotLib: 3.1.1<br/>
TQDM: 4.36.1<br/>
Scikit-Learn: 0.21.3<br/>
Surprise: 0.1<br/>
Scipy: 1.3.0<br/>
Pandas: 0.25.1<br/>
Jupyter Notebook: 1.0.0<br/>
Markdown: 3.1.1<br/>
Numpy: 1.16.4<br/>
Pip: 19.3<br/>
### Folders Structure Explained:
 - ML_Dataset Folder: Contains the Movie Lens Smallest and 27M datasets, it's on .gitignore because all files beyond the original dataset is generated by executing the scripts on this project.
 - tutorials_tf Folder: TensorFlow tutorial that I did just to learn a bit before the project itself, nothing related
 - first_env Folder: Also on .gitignore, it's basically the python virtual enviroment that we are going to install all we need. I caled first because, maybe, in the future, gonna have another ones to try different combinations of libraries like TensorFlow 2.0, Seaborn instead of Malplotlib. But this still not happened
 - main Folder: Literally the main, all the python scripts are here. Divided in the following subfolders:
 -- dataNormalization Folder: Script runned first, to normalize the data and make easier to run the next scripts, you'll run in the following order:
    * rating_norm.py will turn the ratings from range 0.5-5.0 to 0.1-1, in a new file ratings_norm.csv.
    * crop_tags.py will crop the tags that have very little correlation to the movie, if the relevance is lower than 0.3 it'll be cropped off.
    * join_tag_tagid.py will join the column generated by crop_tags with the genome_tags.csv and make a new csv genome_labels.csv that unites all the tags data that matters.
 -- dataPrep folder: The data preparation scripts, this includes the loading of datasets, the long tail crop, the dimensionality reduction and clusterization.
    * longTail_crop.py: It will crop the movies that are too little rated, and the user that evaluated too little movies, to make our data less noisy.
    * user_profile.py: Creates the movie_profile.csv and user_profile.csv the caractheristic vector that define them, in this recommender systems.
    * dim_reductor.py: Will reduce dimensionality in this profiles rewriting this same csv's.
    * movies_cluster.py: Responsible for running the cluster algorithm over the movies dataset, and creating the file: movies_cluster.csv
    * user_cluster.py: Responsible for running the cluster algorithm over the movies dataset, and creating the file: users_cluster.csv
    * load_dataset.py: This one will just load the original csv's into more strategic ones, a training and a test set called training_movies.csv and test_movies.csv