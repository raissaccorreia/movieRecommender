# Recommendation Systems: Ending Computer Engineering Undergrad Project
## Theorical Project in the PDF file:
Latex project made on Overleaf, with it's pdf and images available in this repository:<br/>
**Overleaf**: https://overleaf.com<br/>
**PDF**: On the root folder or in<br/>
**ArXiv**:<br/>
**Images**: On the "Images" folder<br/>
## Practical Project:
### Installing the Venv:
I called venv, and the sequence is in the requirements.txt, suposing the python venv is already installed in your device you will:<br/>
Create the venv called "firstEnv":<br/>
**python3 -m venv firstEnv**<br/>
Activate it:<br/>
**source firstEnv/bin/activate**<br/>
Install jupyter notebook that we'll need to make the work presentable.<br/>
**pip3 install jupyter**<br/>
TensorFlow version 1, for all the machine learning stuff<br/>
**pip3 install tensorflow**<br/>
Keras to make AI models even easier to implement<br/>
**pip3 install keras**<br/>
MatPlotLib for our data visualization<br/>
**pip3 install matplotlib**<br/>
TQDM for ProgressBars in out jupyter notebook or terminal<br/>
**pip3 install tqdm**<br/>
Scikit-Learn for it's extremely efficient implementations of a few famous algorithms<br/>
**pip3 install scikit-learn**<br/>
Pandas for all our dataframes and CSV manipulation<br/>
**python3 -m pip install --upgrade pandas**<br/>
Surprise for some already done recommender algorithms to compare<br/>
**pip3 install surprise**<br/>
Numpy and Scipy for dealing with large arrays<br/>
**pip3 install numpy**<br/>
**pip3 install scipy**<br/>
### Versions that I used:
Python: 3.7.3<br/>
TensorFlow: 1.14.0<br/>
Keras: 2.2.4<br/>
MatplotLib: 3.1.1<br/>
TQDM: 4.36.1<br/>
Scikit-Learn: 0.21.3<br/>
Surprise: 0.1<br/>
Scipy: 1.3.0<br/>
Pandas: 0.25.1<br/>
Jupyter Notebook: 1.0.0<br/>
Markdown: 3.1.1<br/>
Numpy: 1.16.4<br/>
Pip: 19.3<br/>
### Folders Structure Explained:
 - ML_Dataset Folder: Contains the Movie Lens Smallest and 27M datasets, it's on .gitignore because all files beyond the original dataset is generated by executing the scripts on this project.
 - first_env Folder: Also on .gitignore, it's basically the python virtual enviroment that we are going to install all we need. I caled first because, maybe, in the future, gonna have another ones to try different combinations of libraries like TensorFlow 2.0, Seaborn instead of Malplotlib. But this still not happened
 - images Folder: Has the images used in the theorical and the experimental section of the article.
 - main Folder: Literally the main, all the python scripts are here. Divided in the following subfolders:
 -- dataPrep folder: The data preparation scripts, this includes the loading of datasets, the long tail crop, the dimensionality reduction and clusterization.
    * longTail_crop.py: It will crop the movies that are too little rated, and the user that evaluated too little movies, to make our data less noisy.
    * profiles.py: Creates the movie_profile.csv and user_profile.csv the caractheristic vector that define them, in this recommender systems.
    * pca.py: Will reduce dimensionality in this profiles, or try, if reduces in a significant manner will rewrite the old dataset.
    * HDBSCAN_applied.py: Responsible for running the cluster algorithm over the movies dataset, and creating the file: movies_cluster.csv, that wasn't created due to impossibility to cluster the majority of users, and a good chunck of movies.
    * data_split.py: This one will just load the original csv's into more strategic ones, a training and a test set called training_movies.csv and test_movies.csv
    * correct_dataset.py: excess column remover from datasets
-- recommenders folder: The Surprise Library aplication, each file is very similar, some contains grid search like KNN Basic and SVD, all the others are execution with 5-fold cross validations, each has the algoritm name.
-- results: Includes the results from almost all algorithm executions, has the 20K predictions of several algorithms, has the results from GRID Search in KNNBasic_results and SVD_results, has HBDSCAN Fit Results from users and movies, and the PCA results.
    ### Execution Order:
    1) longTailCrop
    2) profiles
    3) correct_dataset
    4) PCA
    5) HDBSCAN_Applied
    6) data_split
    7) KNNBasic
    8) SVD
    9) KNNMeans
    10) KNNBaseline
    11) KNNZScore
    12) Baseline
    13) CoClustering
    14) SlopeOne
    15) NormalPred
    16) NMF
    17) SVDpp
    18) ploting
    
